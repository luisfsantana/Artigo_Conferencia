
%% bare_jrnl.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/te x/testflow/


%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.



% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  \usepackage{epstopdf}
 \usepackage{amsmath,amssymb,exscale}

  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
\usepackage{amsfonts}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lipsum}

% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/

\usepackage[textsize=footnotesize]{todonotes}
\usepackage{times}

%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.


%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley and Jeff Goldberg.
% This package may be useful when used in conjunction with IEEEtran.cls'
% captionsoff option. Some IEEE journals/societies require that submissions
% have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.3.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% For subfigure.sty:
% \let\MYorigsubfigure\subfigure
% \renewcommand{\subfigure}[2][\relax]{\MYorigsubfigure[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat/subfig command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/endfloat/
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{setspace}
\newcommand{\stodo}[2][]
{\todo[caption={#2}, #1]
{\begin{spacing}{1.0}#2\end{spacing}}}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{A Dynamic Load-Balancing Algorithm for Heterogeneous GPU Clusters}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Luis~Sant'Ana,~\IEEEmembership{CMCC-UFABC}
        Daniel~Cordeiro,~\IEEEmembership{DCC-USP}
        and~Raphael~Camargo,~\IEEEmembership{CMCC-UFABC}% <-this % stops a space

\thanks{Luis Sant'Ana is with the Center Mathematics, Computation and Cognition, Federal Uniersity of ABC, Santo Andr\'{e}, SP, Brazil e-mail: luis.ana@ufabc.edu.br}% <-this % stops a space
\thanks{Daniel Cordeiro is with the Department of Computer Science, University of S\~{a}o Paulo, S\~{a}o Paulo, SP, Brazil e-mail: danielc@ime.usp.br }% <-this % stops a space
\thanks{Raphael Carmargo is with the Center Mathematics, Computation and Cognition, Federal Uniersity of ABC, Santo Andr\'{e}, SP, Brazil e-mail: raphael.camargo@ufabc.edu.br}}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
\markboth{IEEE/ACM CCGrid 2015 
15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing}%
{Shell \MakeLowercase{\textit{et al.}}:  Dynamic Load-Balancing}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2007 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
%\boldmath
% DC: Mudei para nao dar a impressao de que mais arquiteturas de GPU eh uma coisa ruim
The use of GPU clusters for scientific applications is becoming more widespread,
with applications in areas such as physics, chemistry and bioinformatics. As the number of different GPU models increases, 
these clusters are quickly becoming more heterogeneous,
with different types of GPUs and CPUs. To use these machines in an efficient
manner, it is necessary to perform load-balancing among the GPUs and CPUs,
minimizing the execution time of the application. We propose an algorithm for
dynamic load balancing in heterogeneous GPU cluster. We implemented the
algorithm in the StarPU framework and compared with existing load-balancing
algorithms.

\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the journal you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals frown on math
% in the abstract anyway.

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
parallel computing, distribuited systems, GPU cluster, GPGPU.
\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\section{Introduction}

% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)
%\IEEEPARstart{T}{he} 
The use of GPUs (Graphics Processing Units) has become popular among
developers of high-performance applications that can benefit from a
large degree of parallelism~\cite{gpu2}. Modern GPUs can have
thousands of simple floating point units (FPUs) that, combined, can be
several times faster than traditional CPUs. The development of efficient GPU
applications is, however, more difficult mainly due to difference on
the amount of available cache memory and on the control logic of the
application.


Many applications already use the processing power of GPUs. For example,
applications in fluid mechanics~\cite{fluid2}, visualization science~\cite{visualization2},
machine learning~\cite{learning2}, bioinformatics~\cite{bioinformatica2} and neural networks~\cite{neural}. However, many complex
problems require the usage of multiple GPUs hosted on different machines (GPU clusters~\cite{raphael, cluster}).


The development of distributed application running on a GPU cluster must also take care of the management of the multiple memory spaces of all GPUs on all nodes of the cluster. This memory spaces are memories that have different characteristics like, speed access and capacity. 

This includes transferring data between these spaces of memories and
ensure the consistency of data. A combination of CUDA (Compute Unified Device
Architecture) and MPI (Message Passing Interface) is a common choice to develop
applications for GPU clusters. There are several efforts by the scientific community for
the creation of new programming models~\cite{appCientificas, wave} for the
development of efficient applications on clusters GPUs~\cite{snucl, Flat, starpu}.

GPU clusters are still typically \emph{homogeneous}. Homogeneity facilitates the development of
applications, since they can be optimized just for a single architecture and is more easy to achieve a good load balance among GPUs. But homogeneity is difficult to maintain in a context
where a new generation of hardware is launched every couple of years.

Developing a load-balancing mechanism that works efficiently for all kinds of applications
is difficult. With two or more GPUs (or even CPUs), this problem is strictly equivalent to the
classic problem of minimizing the maximum completion time of all tasks
(makespan), which is known to be NP-hard \cite{GaJo1979}. An efficient load-balancing scheme must be considered on case by case basis.

For example, there are several studies on
data-parallel applications for that can be divided using domain
decomposition~\cite{Gropp:1992uq} on GPUs. In this case, the data can be easily distributed
among the available GPUs. The main task of the load-balancing mechanism is to
devise the best data division amont the GPUs.  Several scientific applications fit
into this group, including applications in bioinformatics~\cite{bioinformatica2},
neural networks~\cite{neural}, chemistry, physics and materials science.

However, with heterogeneous groups of GPUs, this distribution is more
difficult. There are currently several types of GPUs with different
architectures, such as \emph{Tesla},â€‹ \emph{Fermi}, \emph{Kepler} and
\emph{Maxwell}. These architectures have different organizations of FPUs
(Floating-point Unit), caches, shared memory and memory speeds. A division of the
load based on simple heuristics, such as a the number of cores in the GPU, is
not effective and can be worse than a simple division~\cite{raphael}. Also, 
different architectures require different low-level optimizations and a code can be better
optimized for one architecture than the other. Finally, GPUs clusters normally
have high-end CPUs in addition to the GPUs, and these CPUs may be used by the
applications; for instance, to execute parts of the code which cannot be coded
efficiently using the Single Instruction Multiple Thread (SIMT) model of GPUs.

Another frequent approach is to devise execution time profiles for each GPU type and application task and use it to determine the amount of work given to each GPU. This profiling can be
done statically~\cite{raphael} or dynamically~\cite{acosta, HDSS}. Another
solution is to use simple algorithm for task dispatching, such as the greedy
algorithm from StarPU~\cite{starpu}, where tasks are dispatched to the devices
as soon as they become available.

In this work we propose a novel adaptive algorithm for dynamic load
balancing of data-parallel applications in heterogeneous GPU
clusters. Based on run-time measures, the algorithm creates a execution
model to dynamically adjust the size of data blocks depending on the characteristics of the processing units, both CPUs and GPUs. We have compared the algorithm with a static
approach, which greedily distributes the tasks to every available
device,  with a dynamic approach and with the HDSS~\cite{HDSS} algorithm.

% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}

A common solution for load balancing in distributed systems is to divide the tasks
according to a weight factor representing the processing speed of each
processor. Early approaches used fixed weight factors determined at compile time
with limited success~\cite{Hummel}. But these weight factors are difficult to
determine in heterogeneous GPUs, due to the architectural differences that affect
the performance.

The problem of load balancing in heterogeneous GPUs, began to be studied
recently. Acosta \emph{et al.}~\cite{acosta} proposed a dynamic load balancing
algorithm that interactively try finds a good distribution of work between GPUs
during the execution of the application. A library monitors differences during run-time in each processor. It is a decentralized scheme in which synchronizations are done at each iteration to determine whether there is a need to rebalance the load. Each processor performs a redistribution of workload according to the size of the assigned task and the capabilities of
the assigned processor. Load balancing is obtained by comparing the execution
time of the current task for each processor with the redistribution of the
subsequent task. It this time difference reaches a threshold, a load redistribution is
triggered. Our algorithm is different because is centralized and it creates curves for each
 processing unit, and based on these curves performs the load balancing.

A static algorithm that determines the distribution before starting the
execution of the application, using the static profiles from previous
executions, was also proposed~\cite{raphael}. The algorithm was evaluated using
a large-scale neural network simulation. The algorithm finds the distribution of
data that minimizes the execution time of the application, based on profiles
from previous executions, ensuring that all GPUs to spend same amount of time
performing the processing of kernels. This approach is static and does not allow dynamic
changes in the data distribution.

The Heterogeneous Dynamic Self-Scheduler (HDSS)~\cite{HDSS} provides a dynamic
load-balancing algorithm, divided in two phases. The first is the adaptive
phase, where it determines weights that reflect the speed of each processor.
These weights are determined based on fits of logarithmic curves on processing
speed graphs. These weights are used during the completion phase, where it
divides the remaining iterations among the GPUs based on the relative weights of
each GPU. The main differences to our algorithm is that we do not restrict the
execution models to logarithm curves, which are appropriate for GPUs but not to
CPUs in the range of interest. Also, our algorithm can perform adjustments until
the end of the execution.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Proposed Algorithm}

In a typical data-parallel application, the application data
is divided among the threads in a process called domain
decomposition~\cite{Gropp:1992uq}. The threads then simultaneously process their
part of the data. After finishing, the threads merge the processed results, and
the application terminates or continues to the next phase of computing. The task
of our load-balancing algorithm is determining the size of the data block
assigned to each GPU and CPU in the system. We will use the term processor to
mean a single CPU or GPU.

\vspace{0.2cm}
\paragraph*{Overview} The algorithm has three parts, which are: (1) processor 
performance model, where an execution model for each processor is determined
during application execution; (2) optimal block size selection, where, based on
the performance model, the algorithm selects the best distribution of block size
among the processors; and (3) re-balancing, where the algorithm recalculates the
optimal block sizes when the difference in execution time by different
processors is larger than a threshold.

\begin{figure}[!t]
	\centering
			\includegraphics[scale=0.45]{CPUVersusGPULinear2.jpg} 				
	\caption{GPU and CPU processing times for different block sizes.}
	\label{fig: CPUVersusGPU1}
\end{figure}


\vspace{0.2cm}
\paragraph*{Processor performance model} We initially determine a function
$P_p[x]$, which provides the processing speed for a block of data of size $x$ on
processor $p$. To construct these curves, a block of size $initialBlockSize$,
defined by the user, is allocated to each processor. We select the processor
with the earliest finish time $t_f$ and double the block size for this
processor. For other processors, with finish times $t_i$, we select blocks of
size proportional to the ratio $t_i$/$t_f$.

Figure~\ref{fig: CPUVersusGPU1} shows sample processing time measurements for a
GPU and a CPU for different block sizes. We can see that the curves can be
approximated by linear functions. We find best fit curves by the method of
\textit{least squares}, using a function of the form $f(x) = a x - b$. The
curve is fitted after generating a few points, for example, four, becoming a
model for the processor execution times. The curve can be taken from the time that the determination coefficient is greater than 0.7.


\begin{algorithm}

\caption{Processor performance model}
\label{algModel}

\begin{algorithmic}		

\STATE \textbf{function}~determineModel()

\STATE $blockSizeList \leftarrow initialBlockSize;$
\WHILE{$fitValues.error \geq 0.5$}
		\STATE $finishTimes$ = executeTasks($blockSizeList$);
                \STATE synchronize();
	        \STATE $blockSizeList$ = evaluateNextBlockSizes($finishTimes$);
		\STATE $fitValues$ = determineCurveProcessor();
\ENDWHILE

return $fitValues$;

\end{algorithmic}
\end{algorithm}

These steps are shown in Algorithm~\ref{algModel}. Variable $blockListSize$
contains the size of the blocks assigned to each processor and is initialized
with $initialBlockSize$, which is defined by the user. Variable $fitValues$
contains results from the last least square fitting, including the $error$ in
the fitting, which is initialized as $+\infty$.

In the main loop, while the error is larger than a predefined value, the
function send a chunk of data for each processor and obtain the finish time for
each processor. After waiting for all processor to finish, it determine the
block sizes for the next iteration, based on their finish times. Finally, it
tries to fit model curves to each processor and receives the fitting results.

\vspace{0.2cm}
\paragraph*{Optimal block size selection} Our algorithm determines the optimal
block size for each processor with the objective of minimizing the total time of
the application. Consider we have $n$ processors and a input data size $Z$. The
algorithm assigns a data chunk of size $x^g$ for each processor $g=1,...,n$,
corresponding a fraction of input data, such that $\sum_{g=1}^n x^g = Z$. We
denote as $E^g(x^g)$ the execution time of task $E$ in the processor $g$, for
input of size $x^g$. To distribute the work among the processors, we find a set
of values
	
\begin{equation}
	X = \{ x^g \in \mathbb{R}:[0,1] / \sum_{g=1}^n x^g = Z \}
	\label{eq: totalResultado}
\end{equation}

that minimizes $E_1(x_1)$ while satisfying the constraint

\begin{equation}
	E_{1} = E_{2} = ...= E_{n}
	\label{eq: Restricao}
\end{equation}

which represents that all processors should spend the same amount of time
performing the processing. To determine the set of values $x$, we solve the
system of fitted curves for all processors, given by:

\begin{equation}
	\left\lbrace
	\begin{array}{ll}
		\displaystyle E_{1} = f(x_{1})  \\
		\displaystyle E_{2} = f(x_{2})   \\
		\displaystyle E_{n} = f(x_{n}) 
		\label{eq: system}
	\end{array}
	\right.
\end{equation}

The equations system is solved applying the interior point line search filter
method~\cite{point}. The algorithm seeks to minimize the functions in a search space. Determining the value of $x$ such that the time is minimal.


\vspace{0.2cm}
\paragraph*{Rebalancing} After solving the system of equations the scheduler keeps
sending tasks of size $x_i$ for each processor $i$, as soon as the processor
finishes the previous task. It also monitors the finish time of each task. If
the difference in finishing times $x_i$ and $x_j$ of any two tasks $i$ and $j$
goes above a threshold, the balancing process is re-executed. In this case, the
algorithm applies the processor performance model and optimal block size
selection routines again. The scheduler then synchronizes the tasks and start
using the new $x_i$ values. The threshold needs to be determined empirically through some tests. If the threshold is a value too small, happen unnecessary balancing, which will increase the total time of the application. If the threshold is too large imbalances may arise which will cause threads are idle.

\begin{figure}[!t]
	\centering
			\includegraphics[scale=0.24]{DiagramaArtigo.eps}
	\caption{Threads execution with threshold}
	\label{fig:Diagrama}
\end{figure}

Figure~\ref{fig:Diagrama} shows a diagram of execution of four threads and the unbalance of a thread. The boxes represent the threshold, the lines represent the threads and the circle represents the unbalance. The threads start synchronized, receive load, but in the second step one thread takes longer than the threshold value, this causes an unbalance. Detected unbalance, all threads are synchronized, and the partitions are recalculated for each thread, causing the threads back to stay synchronized. 


\vspace{0.2cm}
\paragraph*{Complete algorithm} Algorithm~\ref{alg1} shows the pseudo-code of 
the scheduling algorithm. The $determineModel$ function, shown in
Algorithm~\ref{algModel} returns the performance model for each processor. It
then solve the system of equations to determine the best distribution $X$ of
chunk sizes for each processor. 

\begin{algorithm}

\caption{Complete dynamic algorithm}
\label{alg1}

\begin{algorithmic}		

\STATE \textbf{function} dynamic()

\STATE $fitValues$ = determineModel()
\STATE $X$ = solveEquationSystem($fitValues$);

\WHILE{there is data}

	\STATE $finishTimes$ = executeTasks($X$);
	\IF {$ $maxDifference($finishTimes$)$ \geq threshold$}
		\STATE $fitValues$ = determineCurveProcessor();
                \STATE $X$ = solveEquationSystem($fitValues$);
                \STATE synchronize();
    	\ENDIF
\ENDWHILE

\end{algorithmic}
\end{algorithm}

The main loop repeats while there is still data for processing. It distributed
chunks of data for each processor in the system, obtaining the finish times for
each task execution. It then checks if the maximum difference between the finish
tasks is above a threshold, obtained empirically. If threshold is reached, the
algorithm fits new model curves and solve the system of equations for these new
curves to determine a new distribution of chunk sizes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implementation}

The implementation was done in the C language with the framework StarPU.
StarPU~\cite{starpu} is a tool for parallel programming that supports hybrid
architectures like multicore CPUs and accelerators. The StarPU proposes an
approach of independent tasks based architecture. Codelets are defined as an
abstraction of a task that can be performed on one core of a multicore CPU or
subjected to an accelerator. Each codelet may have multiple implementations, one
for each architecture in which codelet can be performed using specific languages
and libraries for the target architecture. A StarPU application is described as
a set of codelets with data dependencies.

The tool has a set of scheduling policies implemented that the programmer can
choose according to the characteristics of the application. The main one is the
use of static scheduling algorithm HEFT (Heterogeneous Earliest Finish Time) to
schedule tasks based on cost models of task execution.

For each device one codelet has been programmed with the characteristics of the
devices. A codelet is a structure that represents a computational kernel. Such a
codelet may contain an implementation of the same kernel on different
architectures (e.g. CUDA and x86).  The applications were implemented by
dividing the data set into tasks, implemented as codelets. The tasks are
independent, with each task receiving a part of the input set proportional to
the processor weight. Two codelets were implemented one for GPU/CUDA and one for
CPU architecture.

To evaluate our load-balancing algorithm, we implemented it by modify the default StarPU balancing algorithm. The modification of the load balancing algorithm is realized by changing the STARPU\_SCHED variable. The STARPU framework has an API that allows modifying the scheduling policies. There are data structures and functions that speed up the process of development. For example the function "double starpu\_timing\_now (void)"  return the current date in micro seconds, which makes it easier for the determination of measures runtime. In StarPU there is a data structure called "starpu\_sched\_policy" This structure contains all the methods que Implement a scheduling policy. 

Three other algorithms were implemented for comparison: the greedy, static and
HDSS. The greedy consisted in dividing the input set in pieces and assigning
each piece of input to any idle processor, without any priority assignment. The
static~\cite{raphael}, measures processing speeds before the execution and set
static block sizes per processor at the beginning of the execution, with the
block size proportional to the processor speed. Finally, The HDSS~\cite{HDSS}
was implemented using minimum square estimation to estimate the weights and
divided into two phases: adaptation phase and completion phase.

The library used for solve the equation system like \ref{eq: system} was the IPOPT \cite{point}. IPOPT (Interior Point Optimize) is an open source software package for large-scale nonlinear optimization. It can be used to solve general nonlinear programming problems.

%=========================================================
\subsection{Applications}

For evaluating our algorithm, we adapted two applications from the CUDA
SDK~\cite{cuda} to execute using the StarPU framework, the blackscholes and matrix
multiplication applications. And we adapted a application to gene regulatory networks (GRN) inference~\cite{borelli2013gene}

For the matrix multiplication, we assume that each element in the product matrix
can be obtained by applying the equation \ref{eq: matrix}. A copy of the matrix
A was distributed to all processing units and matrix B was divided according to
the load-balancing scheme, the matrix multiplication version use the shared memory. Matrix multiplication has complexity $O(n^{3/2})$.

Blackscholes is a popular financial analysis algorithm for calculating prices
for European style options. The Black-Scholes equation is a differential
equation that describes how, under a certain set of assumptions, the value of an
option changes as the price of the underlying asset changes. More precisely, it
is a stochastic differential equation that includes a random walk term, which
models the random fluctuation of the price of the underlying asset over time.
The Black-Scholes equation implies that the value of a European call option.


The cumulative normal distribution function, gives us the probability that a
normally distributed random variable will have a value less than x. There is no
closed-form expression for this function, and as such it must be evaluated
numerically. It is typically approximated using a polynomial function. The idea is to calculate the Black-Scholes the greatest amount of possible options. Thus, the input is a vector of data that the options should be calculated by applying the differential equation. The division of the task is given a position of providing input vector to each thread. The complexity of the algorithm is $O(n)$.


Gene regulatory networks (GRN) inference is an important bioinformatics problem in which the gene interactions need to be deduced from gene expression data, such as $microarray$ data. Feature selection methods can be applied to this problem. A feature selection technique is composed by two parts: a search algorithm and a criterion function. Among the search algorithms already proposed, there is the exhaustive search where the best
feature subset is returned, although its computational complexity is unfeasible in almost all situations. The objective of work is the development of a low cost parallel solution based on GPU architectures for exhaustive search with a viable cost-benefit. The complexity of the algorithm is $O(n^3)$.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}


\subsection{System Configuration}

We used three different machines to evaluate our algorithm, presented in table \ref{table: machines}. We performed the experiments with four settings, with one machine (A), with two machines (A, B), with three machines (A, B, C) and four machines (A, B, C and D). 


\begin{table}[!t]
\centering
\tiny
\caption{Configuration of the machines}

\begin{tabular}{|c|c|c|c|c|}
\hline
\multicolumn{1}{|l|}{Machine} & CPU Model & Number of GPUs & \multicolumn{1}{l|}{GPU Memory} & GPU Model\\ \hline
A                             & Intel i7 a20   & 4 x GTX200b         & 896MB                          & GTX 295   \\ \hline
B                             & Intel i7 4930K  & 2 x GK104           & 2GB                            & GTX 680   \\ \hline
C                             & Intel i7 3930K & 2 x GK110          & 6GB                            & GTX Titan \\ \hline
D                             & Intel i7 3930K & 2 x Tesla K20     & 5GB                            & Tesla C2075 \\ \hline
\end{tabular}
\label{table: machines}
\end{table}

To use all the $n$ multiprocessors from a GPU, it is necessary to create at least
$n$ blocks. Moreover, each multiprocessor simultaneously executes groups (called
warps) of $m$ threads from a single block, and several warps should be present
on each GPU for efficient usage of its processors.

In all tests, we used all the multiprocessor of the GPUs, launching kernels with
$k$ blocks per with 1024 threads for each block, where $k$ is the number of
processor in the GPU. For the used GPUs, $k$ is \textbf{14, 8 and 30} in GTX
Titan, GTX 680 and GTX 295 respectively. For the CPUs, we used all the CPU
cores, launching one task per core.


%---------------------------------------------------------------------------

\subsection{Matrix Multiplication}

We evaluated the execution time of the matrix multiplication application using
one, two, three and four machines and four different scheduling algorithms: (1) our
algorithm, (2) static, (3) HDSS, and (4) Greedy. 

\begin{figure}[htb]
	\begin{center}
	\centering
			\includegraphics[scale=0.45]{GraficoMatrizesNovo.eps}
	\caption{Difference in runtime with different sizes of matrices for matrices multiplication}
	\label{fig:todosJuntos}
	\end{center}
\end{figure}


Figure~\ref{fig:todosJuntos} shows the results for matrices with sizes from
4096 x 4096 to 65536 x 65536. In all scenarios, our scheduling algorithms
obtained the best results, with the HDSS algorithm in second. The static and
greedy algorithm were clearly inferior.

With one machine the difference was smaller because there are few types of
devices for the scheduler to select. With two machines our algorithm starts to
perform better, especially for larger matrices, which is explained by the fact
that the execution time of the matrix multiplication increases quickly as we
increase the matrix size. With four machines we have the most heterogeneous
environment and the performance gain using our algorithm is the largest. As in
the other scenarios, increasing the matrix size also increases the performance
gain with our algorithm. For matrices 4096 elements and four machines, the proposed algorithm spent 23.11 seconds while the HDSS spent 29.91, which results in 22.73\% faster. And for matrices 65536, the algorithm proposed spent 383.28 seconds while the HDSS 443.37, which results in  15.67\% faster,  the summary is table \ref{table: comparativo}

\begin{table}[h]
\centering
\tiny
\caption{Compartive: HDSS x Our Algorithm}

\begin{tabular}{c|c|c|c|c|c|c|}
\cline{2-7}
\multicolumn{1}{l|}{}                 & \multicolumn{3}{c|}{Size Matrix 4096 elements}                     & \multicolumn{3}{c|}{Size Matrix 65536 elements}                                       \\ \hline
\multicolumn{1}{|l|}{Num. Machines} & HDSS   & Our Algorithm & \multicolumn{1}{l|}{Differ. (s)} & \multicolumn{1}{l|}{HDSS} & Our Algorithm & \multicolumn{1}{l|}{Differ. (s)} \\ \hline
\multicolumn{1}{|c|}{1 Machine}       & 233.42 & 231.01        & 2.41                                 & 632.13                    & 644.32        & 12.19                               \\ \hline
\multicolumn{1}{|c|}{2 Machines}      & 129.43 & 128.62        & 0.81                                 & 557.92                    & 542.11        & 15.81                                 \\ \hline
\multicolumn{1}{|c|}{3 Machines}      & 36.85  & 28.43         & 8.42             
                   & 473.64                    & 452.41        &            21.23                          \\ \hline
\multicolumn{1}{|c|}{4 Machines}      & 29.91  & 23.11         & 6.8             
                   & 443.37                    & 383.28        &           60.09                          \\ \hline

\end{tabular}
\label{table: comparativo}
\end{table}


The results obtained shows that in more heterogeneous environment the advantage  using our proposed algorithm is largest than the other.
This advantage is due to a better distribution of the data along the
execution. Figure~\ref{fig:diferencaThreads} shows the time difference between
the earliest and latest finishing threads, in the scenario with three machines.

\begin{figure}[htb]
	\begin{center}
	\centering
			\includegraphics[scale=0.4]{Maxima_Diferenca_Matrix.eps}
	\caption{Time differences between the earliest and latest finishing threads}
	\label{fig:diferencaThreads}
	\end{center}
\end{figure}


The greedy algorithm performed well considering that it do not directly
use information on the processing speeds of the devices. But it uses this
information indirectly, since faster devices finish their tasks earlier and,
consequently, receive more tasks. The static algorithm had the worst performance, because it leaves the thread idle for a long time see \ref{fig:diferencaThreads}. There are big differences among end of threads.

HDSS uses the beginning of the execution to estimate the best block size
distribution and uses this distribution through the complete
execution. Moreover, larger blocks are used in the beginning of the execution,
causing a larger delay due to dis-balance when use different types of devices,
such as GPUs and CPUs. Finally, HDSS uses a crude approximation to the device
capabilities.

Our algorithm estimate fairly accurately the amount of data that should be
provided to each processing unit, solving an optimization problem with the
restriction that all units should finish the execution of the tasks at the same
time. When the difference between finishing the execution of threads for certain
data partition exceeds a certain threshold, the algorithm re-balances the data
distribution.

%---------------------------------------------------------------------------
\subsection{Blackscholes}

\begin{figure}[htb]
	\begin{center}
	\centering
			\includegraphics[scale=0.45]{BlackScholes4Machines.eps}
	\caption{Difference in runtime with different number options}
	\label{fig:black}
	\end{center}
\end{figure}

We evaluate the execution time of the Blackscholes application using different
machine configurations. Figure~\ref{fig:black} shows the execution times, where
we varied the number of options on each execution and obtained the
runtimes. Similarly to the matrix multiplication experiments, the performance
gains were the largest with bigger problem sizes (number of options) and more
heterogeneous environments, and the results can be explained using the same
arguments. Interestingly, the Blackscholes application has linear complexity
with the number of options, showing that our scheduling algorithm is also useful
with this class of application. The table \ref{table: black} shows the extreme values â€‹â€‹of 10,000 and 500,000 options, the best result was with 4 machines, and with the greatest number of options.


\begin{table}[htb]
\centering
\tiny
\caption{Compartive: HDSS x Our Algorithm}

\begin{tabular}{c|c|c|c|c|c|c|}
\cline{2-7}
\multicolumn{1}{l|}{}                 & \multicolumn{3}{c|}{10,000 Options}                              & \multicolumn{3}{c|}{500,000 Options}                                                  \\ \hline
\multicolumn{1}{|l|}{Num. Machines} & HDSS (s) & Algorithm (s) & \multicolumn{1}{l|}{Diff. (s)} & \multicolumn{1}{l|}{HDSS (s)} & Algorithm (s) & \multicolumn{1}{l|}{Diff. (s)} \\ \hline
\multicolumn{1}{|c|}{1 }       & 6.52     & 6.56              & -0.04                          
			 & 8.61                          & 8.59              & 0.02                           \\ \hline
\multicolumn{1}{|c|}{2 }      & 4.65     & 4.41              & 0.24                            
				& 6.62                          & 6.51              & 0.11                            \\ \hline
\multicolumn{1}{|c|}{3 }      & 1.31     & 1.24              & 0.07                            
			& 3.45                          & 3.11              &               0.34                  \\ \hline
\multicolumn{1}{|c|}{4 }      & 1.11     & 1.02              & 0.09                       
			    & 2.93                          & 2.72              &               0.21                  \\ \hline
\end{tabular}
\label{table: black}
\end{table}

Also, considering that the application finishes in less than 4 seconds, for the
scenario with 4 machines, we also see that the cost of solving the optimization
problem to determine the best data distribution is small and the obtained gains
outweighs the cost of the calculations. For applications tested in a few
iterations around 6, it was possible to obtain the solution of the system in a
few milliseconds. The total cost of calculating the distribution of the blocks is 660 
milli seconds.

\begin{figure}[htb]
	\begin{center}
	\centering
			\includegraphics[scale=0.4]{Maxima_Diferenca_BlackScholes.eps}
	\caption{Time differences between the earliest and latest finishing threads}
	\label{fig:diferencaThreadsBlack}
	\end{center}
\end{figure}

Figure~\ref{fig:diferencaThreadsBlack} confirms this result, showing that the
time difference among the earliest and latest finishing threads, in the
scenario with four machines is always smaller for our proposed algorithm.


\subsection{Gene regulatory networks inference}

As in previous applications, we compare the execution time in four different environments: with  one machine, two machines, three machines and four machines. The results are shown in \ref{fig:Gene}. We can notice that our algorithm outperformed in four cases. Especially in the case that three and four machines were used. 

\begin{figure}[htb]
	\begin{center}
	\centering
			\includegraphics[scale=0.4]{GraficoFabrizio4maquinas.eps}
	\caption{Difference in runtime with different numbers of genes for gene regulatory network inference}
	\label{fig:Gene}
	\end{center}
\end{figure}

The table \ref{table: gene} shows the extreme valuesâ€‹â€‹, for 100,000 and 2,000,000 genes. 
To the environment with 3 and 4 machines the performance were similar due to limitation in data transfer, in the case of four machines the communication cost limited the gain. (HipÃ³tese)

\begin{table}[htb]
\centering
\tiny
\caption{Compartive: HDSS x Our Algorithm}

\begin{tabular}{c|c|c|c|c|c|c|}
\cline{2-7}
\multicolumn{1}{l|}{}                 & \multicolumn{3}{c|}{100,000 Genes}                              & \multicolumn{3}{c|}{2,000,000 Genes}                                                  \\ \hline
\multicolumn{1}{|l|}{Num. Machines} & HDSS (s) & Algorithm (s) & \multicolumn{1}{l|}{Diff. (s)} & \multicolumn{1}{l|}{HDSS (s)} & Algorithm (s) & \multicolumn{1}{l|}{Diff. (s)} \\ \hline
\multicolumn{1}{|c|}{1 }       &197.94     & 116.43              & 81.51                          & 927.43                         & 889.13              &           38.30                  \\ \hline
\multicolumn{1}{|c|}{2 }      & 79.76     & 53.43              & 26.33                            & 702.65                          & 632.73              & 69.72                           \\ \hline
\multicolumn{1}{|c|}{3 }      & 34.76     & 21.39              & 13.37                            & 502.65                          & 432.43             &               70.22                  \\ \hline
\multicolumn{1}{|c|}{4 }      & 25.91     & 18.54              & 12.63                            & 479.54                          & 411.46             &               68.08  \\ \hline
\end{tabular}
\label{table: gene}
\end{table}

Like the other experiments, the maximum difference among the threads followed the same principle. Our algorithm has the smallest difference among the threads, figure \ref{fig:GeneDiferenca}.

\begin{figure}[htb]
	\begin{center}
	\centering
			\includegraphics[scale=0.4]{Maxima_Diferenca_Fabrizio.eps}
	\caption{Difference in runtime with different numbers of genes for gene regulatory network inference}
	\label{fig:GeneDiferenca}
	\end{center}
\end{figure}

In the figure \ref{fig:GeneBlocos} we compare the behavior in relation to submission of blocks among machines. It analyzed the block size for the HDSS and our algorithm. In this case three machines were used, it is possible to notice the difference between runs. Our algorithm in step 400 suffered a re-balancing, causing it to change the size of the block. In HDSS, a decrease of the block size remains over the iterations.

\begin{figure}[htb]
	\begin{center}
	\centering
			\includegraphics[scale=0.4]{BlocosComportamento_Fabrizio.eps}
	\caption{Difference in runtime with different numbers of genes for gene regulatory network inference}
	\label{fig:GeneBlocos}
	\end{center}
\end{figure}
%-------------------------------------------------------------------------------
\section{Conclusions and future work}

In this paper we propose an algorithm for scheduling tasks in domain
decomposition problems executing on clusters of heterogeneous CPUs and GPUs. It
outperforms other similar existing algorithms, due to the online estimation of
the performance curve for each processing unit and the selection of the best
data distribution for the devices. We showed for two applications that our
algorithm provides the highest gains for more heterogeneous and larger problems
sizes.

Although we used dedicated clusters, we can also consider the usage of public
clouds, where the user can request a number of resources allocated in virtual
machines from shared machines. In this case, the quality of service may change
during execution, and the addition of the execution time difference threshold
permits readjustments in data distributions. We can also consider the scenario
with added fault-tolerance, where machines may become unavailable during
execution. In this scenario, a simple redistribution of the data among the
remaining devices would permit the application to readapt to this scenario.

As ongoing work, we are including the cost of communication in the scheduling
algorithm, which is essential for applications where the time spent with
information exchange among the tasks cannot be ignored.

% use section* for acknowledgement
\section*{Acknowledgment}


The authors would like to thank FAPESP (Proc. n. 2012/03778-0 and Proc. n.  2013/14603-9) for the financial support.


\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
% File .bib
\bibliography{article}


\end{document}


